\documentclass[11pt]{article}
\usepackage{fullpage}
\usepackage{amssymb}
\usepackage{url}
\usepackage{parskip}

\title{Twig for GPUs...}
\author{Geoffrey C. Hulette}

\begin{document}
\maketitle
\thispagestyle{empty}

\section{Introduction}

Programming for GPUs can be a challenging task. There is a considerable amount
of protocol that must be invoked in order to set up and release the device,
move data to and from the device, synchronize processing at barriers. Yet for
many problems, the logic is fairly simple -- perform some function on a vector
or array.

This pattern suggests that programmers should consider abstracting the
interface to the GPU, so that they can focus on domain logic and ignore the
tedious details of interacting with the device. There are numerous ways to
approach this problem.

First, programmers could build a library of functions or objects which hide as
many details as possible. In fact this has already been done to a large
extent, with frameworks such as CUDA or OpenCL, and these libraries are the
primary way in which programmers already program for GPUs. This approach
mitigates many difficult issues, but provides only a minimal abstraction --
the library abstraction cannot hide the need to coordinate GPU activities such
as set up and memory management. Programmers might try to create their own
libraries on top of CUDA or OpenCL, but in most languages the object or
library facilities will not allow them to reason at a high semantic level. In
other words, they might be able to simplify some operations by specializing
them (e.g. ignore the possibility for multiple devices), but they cannot hide
them altogether.

Another approach is to design a domain-specific language for GPUs. Examples
include PyCUDA or MPI for GPUs. Domain-specific languages are typically not
customizable for higher-level application logic.



% \section{Section Title}
% \input{section_file}

% \pagebreak
% \bibliographystyle{plain}
% \bibliography{references}

\end{document}
