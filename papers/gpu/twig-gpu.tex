\documentclass[11pt]{article}
\usepackage{fullpage}
\usepackage{amssymb}
\usepackage{url}
\usepackage{parskip}

\title{Twig for GPUs}
\author{Geoffrey C. Hulette}  %% and Matt, and probably Al -- he should
%% have input on this once we're at a state where the ideas are all here.
%% he has a strong interest in GPUs, so I bet this will get his attention.

\begin{document}
\maketitle
\thispagestyle{empty}

\section{Introduction}

Programmers are often constrained by engineering requirements to
produce work in a mainstream language such as C or Java.  At the same
time, there is an increasing awareness of the benefits of
\emph{domain-specific} programming languages (DSLs) for letting
programmers focus on the problem they are solving instead of tedious
fine-grained implementation details. The goal of DSLs is to closely
model the problem domain that a programmer is working within, which
has a number of benefits. First, the reduction in abstraction from
algorithm statement to a corresponding implementation that is required
by traditional languages is avoided, allowing them to be expressed
clearly and succinctly in a DSL. Second, DSLs may admit automated
reasoning about programs, such as optimization for efficiency in
running time or space requirements, or proving that the program
adheres to required constraints such as variable value ranges. Where a
DSL provides these benefits and also generates C (or some other
mainstream language) as output, it may be useful and relatively easy
to integrate with existing engineering processes.  Furthermore, domain
specific languages reside at a higher level of abstraction than
traditional languages, allowing them to be more easily retargeted to
new architectures due to a lack of specificity regarding how high
level algorithms should be mapped to specific architectures.  This
final benefit is particularly attractive for non-traditional processor
architectures emerging in the market at present.

The power of DSLs comes at a cost, however. DSLs typically have a unique
syntax and semantics that may be known primarily to the language's author. The
interpreter and other tools may be difficult to support or extend if the
original author becomes unavailable. It can also be difficult to extend DSLs
to support new constructs or rules. This has been a long standing argument
in favor of continued preference for traditional general purpose programming
languages.

We introduce Twig, a DSL intended for ``ad-hoc'' modeling of a variety of
high-level program semantics, and admitting simple reasoning via equivalence
rules. The evaluation of a Twig program generates code in C (and potentially
other languages), lending it to integration in software existing projects. By
``ad-hoc'' we mean that Twig can be configured rather easily by application
programmers to serve as a DSL for different purposes, even within the same
application. This may alleviate some of the resistance to the adoption of
Twig-based DSLs in projects. %% Matt - this paragraph needs more work.  Why
%% does twig help fix the problems pointed out above?

In this paper, we demonstrate how Twig can be used to build a domain specific
extension to traditional languages like C to address what we believe are
limitations to existing type systems that complicate the programming of
hybrid architectures such as those based on GPGPUs.  All mainstream
languages are based on an assumption that the underlying architecture, either
via hardware assistance or software runtime support, provides the illusion
of a single addressable memory accessible by all cores within a computer.
Hybrid systems violate this by partitioning memory between processors of 
different types (such as a CPU and GPU), and forcing data movement between
these memories to be explicitly stated.  Traditional languages must be
extended to abstract away the management of this data movement.  This paper
shows how Twig can be used to move this into the type system of a traditional
language via a domain specific extension.  % Too wordy, but ...

%% NOTE: for related work, definitely call out HPF.  HPF was interesting
%% because it explored extending the type system of Fortran 90 to add
%% data distribution information, which feels similar to the twig gpu idea.
%% definitely need to talk about that at some point in the paper.

%% old text
%In this paper, we demonstrate how Twig can be used to describe some simple
%kinds of GPU programming. GPU programming is a good example of the kinds of
%problems we anticipate Twig being useful for -- it has a fairly simple
%high-level structure (described below) but is tedious and complicated to write
%by hand. % Matt - this is weak as well.
%% old text

\section{Example Problem: GPGPU Programming}

Programming for GPUs can be a challenging task. There is a
considerable amount of protocol that must be invoked in order to set
up and release the device, move data to and from the device,
synchronize processing at barriers. Yet for many problems, the
\emph{computational logic} of a program is fairly simple to state --
perform some function on a vector or array.  Current GPGPU programming
techniques require this computational logic to be intermixed with the
\emph{protocol logic}, resulting in programs that are complex to write,
maintain, and tune for performance.  Composition of independently developed
program units that use the GPGPU is similarly complex due to limited (or
nonexistent) methods for reasoning about the result of this composition in
terms of lower level memory usage and task creation.

This pattern suggests that programmers should consider abstracting the
interface to the GPU that constitutes the protocol logic of the
program, so that they can focus on the domain oriented computational
logic of the program.  This will allow them to avoid obfuscating their
computatuonal logic with the tedious details of interacting with the
device. There are numerous ways to approach this problem.

First, programmers could build a library of functions or objects which hide as
many details as possible. In fact this has already been done to a large
extent, with frameworks such as CUDA or OpenCL, and these libraries are the
primary way in which programmers already program for GPUs. This approach
mitigates many difficult issues, but provides only a minimal abstraction --
the library abstraction cannot hide the need to coordinate GPU activities such
as set up and memory management. Programmers might try to create their own
libraries on top of CUDA or OpenCL, but in most languages the object or
library facilities will not allow them to reason at a high semantic level. In
other words, they might be able to simplify some operations by specializing
them (e.g. ignore the possibility for multiple devices), but they cannot hide
them altogether.

Another approach is to design a domain-specific language for GPUs. Examples
include PyCUDA and OpenMPC. Domain-specific languages are typically not
customizable for higher-level application logic.

\subsection{The Twig Approach}

% what is the twig approach?  Give a little info here.

A key milestone in the history of programming languages was the
introduction of high level types into early languages.  The ability of
programmers to separate the representation of a value of different
types (e.g., floating point versus integer; record types; arrays)
allowed program code to be written in terms of the mathematical
abstractions that bits in memory represented without exposing how the
values were laid out in memory.  We believe that a similar type-level
abstraction is possible in modern hybrid computer architectures.  The
abstraction that must be moved to the type system is that of the location
of data within the system.  

Changes in representation of basic values, such as integers or floats, is
often as simple as a type casting operator or an implicit type conversion
as allowed by the language.  If residence information about data is part of
the type system, then movement of data within the memory hierarchy of a hybrid
machine can also be made as simple to express as traditional type coercions.
For the domain of GPGPU programming, Twig allows a domain specific type
system to be created in which this additional location information can be 
added to the type of variables with corresponding type coercion operatiors
that map to lower level memory movement logic that defines the protocol between
the host and GPU device.

In addition, by abstracting the protocol operations away to high level
type coercion operators, Twig can support automated reasoning about
programs that allows optimizations to be performed related to the underlying
protocol logic.  For example, if a programmer defines a sequence of
statements that, based on their type, state that data will move back and forth
between the host and device without modification on the host side, unnecessary
copies of data can be removed.  This will increase program performance by
reducing unnecessary burden on the memory subsystem.

Current systems like CUDA and OpenCL allow the programmer to explicitly
allocate memory on one of the many devices that control some portion of 
the memory within a machine, but require copies to be explicitly implemented
by the programmer.  The result is fine grained control of the machine at the
cost of limited analysis and optimization of data movement within the memory
hierarchy.  This makes writing complex programs difficult, particularly with
respect to performance.  We believe that a Twig-based DSL for GPU programming
based on extending the type system of existing languages is a step towards
removing this burden from the programmer.

\section{Related Work}

Discuss PyCUDA and OpenMPC. What about Jacket and other GPU-type interfaces
for languages like Matlab?

Yampa?

Other general-purpose DSLs?

Accelerate GPU language in Haskell is similar.  

\section{Twig}

Overview of how Twig works, basic semantics, code generation, simple example.

Focus on importance of generating C - integration with existing methods, type-directed generation.

\subsection{Reductions}

Explain reductions and how they can be used in domain- or application-specific
ways.

Explain built-in reductions. Maybe discuss idea of a normal form, although
this might be better in a later paper.

\section{Implementation}

Talk briefly about how Twig is implemented, and how to use it to generate
code.

\section{Evaluation}

Show some GPU algorithm encoded in Twig. Discuss advantages over simple APIs
(restricted flexibility equals improved ability to reason).

Show how reductions eliminate redundant copies.

Compare performance versus naive generation.

Also compare against PyCUDA or another system?

\section{Future work}

Future work.

\section{Conclusion}


% \section{Section Title}
% \input{section_file}

% \pagebreak
% \bibliographystyle{plain}
% \bibliography{references}

\end{document}
