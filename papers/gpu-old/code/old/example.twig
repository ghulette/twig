-- This example ignores some important stuff:
-- 1. Things like SIZE and N are treated as constant parameters; they could  
--    instead be passed as data through tuples, or as block parameters.
-- 2. No cleanup (free, cudaFree, etc.). This can be handled by closing blocks, 
--    but right now this is C specific and I don't have a good syntax for it.
-- 3. I thought we were ignoring barriers, but it turns out that cudaMemcpy 
--    conveniently includes a barrier anyway.

copyToGPU = [array(float) -> gpu(array(float))] {
  cudaMalloc((void **) &$out, SIZE);
  cudaMemcpy($out, $in, SIZE, cudaMemcpyHostToDevice);
}

copyFromGPU = [gpu(array(float)) -> array(float)] {
  $out = malloc(SIZE * sizeof(float));
  cudaMemcpy($out, $in, SIZE, cudaMemcpyHostToDevice);
}

kernel{k} = [gpu(array(float)) -> gpu(array(float))] {
  $k <<< N_BLOCKS, BLOCK_SIZE >>> ($in, N);
  $out = $in;
}

runKernel{k} = copyToGPU;kernel{k};copyFromGPU

main = runKernel(foo);runKernel(bar)

@reduce copyArrayFromGPU;copyArrayToGPU -> id
