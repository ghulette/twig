%!TEX root = twig.tex

\subsection{Interface definition languages}
\label{idls}

Interface definition languages (IDLs) are a popular approach to interoperability~\cite{kaplan98idl}. An IDL describes an interface to a software \emph{component} (see below), in terms that are abstracted as much as possible from the underlying implementation language, operating system, architecture, network protocol, and so on. The goal of this abstraction is to allow the software to be reused in many contexts. Here, we are interested in the ways that IDLs permit components written in different languages to interact.

A key concept in IDL-based systems is \emph{marshalling}. IDLs are used to generate code that implements the abstract interface they describe in some target language. Among other things, this involves deciding which types in the target map to those of the IDL. IDLs usually specify some binary format for data in their type system so that it can be moved from place to place and interpreted in different languages or systems. The process of translating data from a language's native representation to that of the IDL is called \texttt{marshalling}. The reverse process, translating from the IDL representation to a native data format, is called \texttt{unmarshalling}.

Although details vary, IDL systems often work by generating \emph{skeleton} and \emph{stub} code. Skeleton code implements a template of the IDL-specified interface in some target language. The skeleton handles unmarshalling the arguments, invoking the correct function, and marshalling the return value. The skeleton contains \emph{hooks}, i.e., spaces for an implementation of the interface functions to be filled in by the programmer. The stub code presents the interface in the target language, usually as a set of callable functions. Stub code marshals the arguments, finds and invokes the corresponding skeleton function, and unmarshals the return value. The stub and skeleton code work together to hide the complexities of the framework from the programmer.

There are many different IDLs, a fact which in itself deters from the IDLs goal of maximal interoperability. This proliferation reflects the challenge of designing an abstract interface language that is interoperable with many different languages, while easy to use in any given language.

In this section we give an overview of components and remote procedure calls, two branches of software design where IDLs play an important role. Then we provide examples of several IDL-based systems, and conclude with a discussion of the reasons why IDLs are popular and some of the weaknesses they entail.

\subsubsection{Components}

A software component, generally, is a piece of code that is intended to be reused. The exact definition is a matter of some debate~\cite{hopkins00component}. A reasonable, inclusive definition might be ``a physical packaging of executable software with a well-defined and published interface''~\cite{hopkins00component}. Software components are generally designed to be composed and reused by third parties, i.e., by programmers other than those who wrote the component itself.

Most component systems use IDLs to describe component interfaces~\cite{vinoski97corba}. IDLs allow components to be written in whatever language is most appropriate or convenient, while still presenting an interface that other components can consume. This approach to multi-language programming potentially allows many different languages to interoperate, in contrast to FFIs which allow only two~\cite{grechanik04polylingual}.

Component-oriented software engineering describes a method for building software that consists entirely of composing systems of components~\cite{armstrong99common, kohn01babel}. Components in this model are classified by their role and origins~\cite{vinoski97corba}. The most general-purpose components are those needed by many different kinds of applications (e.g., database access services, graphics, and so on). An application programmer rarely creates these kinds of components from scratch, since they are often available from third parties, and may be difficult to create. A middle tier of component generality encompasses those components that are needed by many applications within a particular domain. For example, many medical applications may need to access DICOM format images~\cite{dicom}. These components may expose a somewhat less general interface, if widely-used standards exist for the domain. These kinds of components are also rarely written solely by an application programmer, but large application developers may often contribute to or improve the components. Finally, there are application-specific components. These are always written by the application developer, and may be difficult to reuse outside the application context for which they are created. These components may implement things like a specific graphical user interface for the application.

A \emph{component framework} is required to instantiate components, manage their execution and interoperation, and provide semantics for component composition~\cite{nierstrasz95composition}. As we will see in the examples, the exact definition of a component is usually tied to the framework in which it operates~\cite{hopkins00component}.

Component-oriented programming has several important advantages
over traditional techniques~\cite{nierstrasz95composition}. First,
it has been shown to simplify the design of large applications by
decomposing them into smaller parts. Second, it increase
flexibility, as component-based applications may be recomposed
and/or augmented in response to changing requirements. The
drawback to component-based software is the increased time and
effort required to design component interfaces, and to ensure that
components conform to the framework's requirements. Component
frameworks may also entail some performance costs. Finally, use of
an IDL often restricts the form of composed
interfaces~\cite{kaplan98idl}. We examine this last drawback in
more detail in Section~\ref{idl_discussion}.

%%
%% EXAMPLES
%%

\subsubsection{Examples of component frameworks}

In this section we examine component frameworks that provide connections between components written in multiple languages. There are other important component frameworks, including Enterprise Java Beans (EJB)~\cite{demichiel06ejb, panda07ejb} and Microsoft's Component Object Model (COM)~\cite{comobjects} that we omit here because they do not support multi-language programming.

\paragraph{CORBA}

The Common Object Request Broker Architecture (CORBA)~\cite{vinoski97corba} is a large and popular component framework standard. Components in CORBA are called ``objects,'' although they are quite different than the notion of objects in object-oriented programming languages. In particular, CORBA components have a unique identifier, are created once, and then are accessed only through an interface which is defined in CORBA's IDL (described below).

The CORBA standard describes a framework that is based on an ``Object Request Broker'' (ORB), which acts as a backplane for inter-component communication. Every component in a CORBA system has access to the ORB. Many CORBA ORB implementations provide support inter-ORB communication, even to other ORB implementations~\cite{vinoski97corba}. The ORB has many functions, including services that allow components to be looked up either by name or by interface.

The ORB encapsulates almost all aspects of a component, isolating them from other components except for the IDL-defined interface. Hidden properties include the network location of the component, implementation details including the programming language used to write the component, and the execution state of the component (uninitialized, idle, or currently servicing a request).

CORBA's IDL is simple by design, so that as many languages as possible may be used to write CORBA components. The IDL is used to construct an \emph{interface}, which components may then choose to \emph{provide}. An interface which can be thought of a set of functions with names and associated argument and return types. When a component provides an interface, it implements the functions described in the interface, using the appropriate types. CORBA can generate skeleton and stub code from an interface for any language that the implementation supports.

The IDL allows functions to take any fixed number of arguments, and to return a single value. Each argument and the return value must have a type, and the available types are specified by the IDL. The types include a set of precisely specified primitive numeric types (e.g., 8-, 16-, 32-, and 64-bit integers, booleans, 32- and 64-bit floating point numbers), and both ASCII and Unicode characters. There are fixed- and variable-length strings and lists. There are also constructed types, such as structure and union types similar to those in C, and a special ``any'' wildcard type. Finally, there is an interface reference type for CORBA interfaces, which can be used to pass typed references to components. Since many languages do not support pointers, the IDL intentionally lacks explicit pointer types.

The CORBA IDL requires that each function argument be marked as
\texttt{in}, \texttt{out}, or \texttt{inout}, to indicate its
directionality. Arguments marked \texttt{in} are effectively
passed by value, and changes to the value within the function will
not be propagated back to the caller. Arguments marked
\texttt{out} are references; their initial value from the caller
is ignored, but changes within the function will modify the
referenced value in the caller's context. Arguments marked as
\texttt{inout} are treated like \texttt{out} arguments, but their
value at input is not ignored.

For a programming language to support CORBA, a mapping must be defined from CORBA's type system to the language's type system, and vice-versa. Because the CORBA IDL specifies a fairly limited and common set of types, this mapping is straightforward for many languages. For example, in a C compiler, a CORBA string maps to a \texttt{char *}. In C++, it may be mapped to a \texttt{std::string}.

Language interoperability is realized by the CORBA IDL's type system, which acts essentially as a commonly-understood, intermediate format for data exchange across languages. Note that since the IDL includes a notion of references to other components, it also allows CORBA to act as a kind of FFI between any two languages that the implementation supports, allowing function calls from one language to another.

In practice, many popular languages provide support CORBA integration in the form of a mapping from their basic types to CORBA's IDL~\cite{vinoski97corba}. This support makes CORBA a practical choice for multi-language programming scenarios that require interoperation of two languages which do not have a dedicated FFI. It is also useful for situations where more than two languages are required.

\paragraph{CCA}

The Common Component Architecture (CCA)~\cite{armstrong99common} is a component framework for high-performance scientific applications. CCA is strongly influenced by CORBA, and the two systems have much in common.

Scientific application developers are good candidates to adopt component-based software engineering. Reuse of highly complex and specialized scientific codes is highly desirable, and the nature of scientific research, especially the need for repeatable experiments, encourages sharing~\cite{kohn01babel}. The CCA was created to address these requirements.

% TODO: Break out Babel into its own section.

CCA describes component interfaces using an IDL called called SIDL~\cite{smolinski99interop}. SIDL is essentially an extension of CORBA's IDL that adds types of particular interest to scientists. These include multi-dimensional arrays (with either fixed or dynamic size) and complex numbers. A tool called Babel implements a SIDL parser, and can generate stub and skeleton code in C, C++, Fortran 77, Fortran 90, and Python.

In CCA, interfaces are called \emph{ports}. A component may \emph{provide} a port, which means that the component implements functions that match those described in the port. A component may also declare that it \emph{uses} a port. This means that the component requires an implementation of a component that provides that port to be loaded in the component environment. This system allows for different components that provide the same functionality (i.e., provide the same port) to easily be swapped in and out of an application~\cite{armstrong99common}.

CCA does not currently support type mapping (see Section~\ref{sec:background:typemap}) beyond the default primitive and structure maps in CORBA, although recent work has been moving towards this goal~\cite{onramp}.

\paragraph{Cactus}

Cactus~\cite{goodale07expressing, goodale03cactus} is a component framework with a focus on scientific applications. It does support components written multiple languages, but it does not use an IDL. Instead, it limits the languages that components may be written in to C, C++, and Fortran, and uses their existing interoperability facilities for inter-language component communication. In particular, C++ can call C functions directly since C++ is derived from C and shares much of its architecture, and Fortran has a bi-directional FFI to C (see Section~\ref{sec:ffi}).


%% 
%% RPC
%%

\subsubsection{Remote Procedure Calls}

Remote procedure call (RPC) is an approach to inter-process communication, where each participating processes is assumed to be running on a separate computer connected by a network~\cite{hayes87mixed, birrell84rpc, tay90rpc, hansen20origin}. The mechanism disguises itself as a procedure call, but after the call is made, the RPC system packages the function and its arguments in a binary message, and sends it to be handled by some other process. How the receiving process is chosen and located is a feature of the particular RPC system, and in general the receiver may be running on a different machine. After the message is received, the function and arguments are decoded, the function is executed, and the return value is passed back to the calling process. When the caller receives the response, it decodes the value and returns it via the regular function call return mechanism. From the caller's point of view, this entire process is indistinguishable from a regular function call.

RPC's straightforward semantics have made it a popular approach to distributed programming~\cite{tay90rpc}. Also, and more importantly for our purposes, RPC systems usually allow for multi-language programming~\cite{hayes87mixed}. Their use of IDLs to describe exposed procedures has the effect of abstracting language-specific details, allowing for RPC to work across any language that supports the particular RPC protocol.

In fact, RPC can be thought of as a general approach to handling heterogeneity in computing systems~\cite{notkin88interconnect}, since it can be designed to abstract different operating systems, machine architectures, programming languages, and networking, all under the guise of a simple procedure call.

Both component frameworks and most RPC systems make use of IDLs~\cite{hayes87mixed}. In RPC, the units of interoperability described by the IDL are procedures or functions rather than components, but the approach is very similar.

Two models of RPC semantics are popular: blocking and non-blocking~\cite{tay90rpc}. The blocking model uses strives to emulate the semantics of a normal procedure call, i.e., from the point of view of the caller, execution is suspended until the call returns. In the non-blocking model, the call is still made normally, but for the caller, execution continues immediately and does not wait for the remote call to return. Later, the caller can use the RPC's API to check whether or not a response has been received, and to collect the return value if one is available. Many systems provide both blocking and non-blocking calls. For the purposes of language interoperability, the distinction is immaterial.

RPC designs generally favor hiding the details of the network communication from the caller. Ideally, the caller need not even be aware of whether a call is remote or local. This abstraction principle is somewhat leaky, however. First, RPC calls must generally avoid passing arguments that are tied to the local address space (e.g., a pointer to an array), since the callee might be located in a separate address space. Second, the possibility of network errors implies that RPC systems must handle failures that regular procedure calls do not~\cite{birrell84rpc, notkin88interconnect}. For example, the correct semantics for RPC are unclear if the network stops functioning entirely, and must be defined by the implementation or standard. More subtle network failures are also possible, and RPC systems must be careful in the design of their protocols to ensure that, for example, failures do not cause a single call to result in more than one execution of a remote function~\cite{spector82remote}.

There are several issues in RPC systems that we will not examine here because they are not relevant to our discussion of multi-language programming. In particular, RPC systems are often concerned with their performance under different network configurations and parameters, as well as the security implications of exposing program functions on the network~\cite{tay90rpc}.

\subsubsection{Examples of RPC systems}

In this section we will examine several RPC systems and show how
they facilitate multi-language programming. One important RPC
system, Java Remote Method Invocation (RMI), is omitted because it
is tied to Java and does not directly support multiple
languages~\cite{waldo98jrmi}.

\paragraph{Sun RPC}

Sun RPC introduced the ``External Data Representation'' (XDR), an influential and at the time innovative IDL design~\cite{coulouris94sunrpc}. Sun RPC was originally designed to enable network distributed function calls to and from C, and not necessarily for inter-language function calls. So, XDR's data types look a lot like those of C. In addition to the usual primitive types (integers, floating point, characters, and so on), XDR supports C-style structures and unions, although these may only be one level deep (e.g., no \texttt{struct}s within \texttt{struct}s). XDR also supports fixed-length strings, as well as fixed- and variable-length arrays of primitives. Finally, XDR supports an ``opaque'' data type, that represents a sequence bytes guaranteed not to be modified by marshalling and unmarshalling~\cite{rfc1832}. XDR does not support explicit pointer types, since a raw pointer value has no valid interpretation outside its local address space. The mappings to and from these types and their representations in C are fixed by XDR.

% TODO: Give some context on the need for XDR in NFS.

XDR was designed for C, and C's native data representation is tied to the machine architecture and compiler. This explains why XDR's binary data representation is so precisely specified, since it must accommodate marshalling between data formats that may have different integers lengths, different endianess, different ways of packing \texttt{struct}s, and so on. This is also why XDR is a useful system for interlanguage communication -- by abstracting the data transport representation from the in-language representation, and keeping its supported set of types minimal and fairly universal, XDR becomes a language-independent standard.

\paragraph{ILU}

Inter-Language Unification (ILU) goes beyond traditional RPC systems in two ways. First, it explicitly focuses on facilitating multi-language programming through an RPC-based approach. Second, it creates a system where objects may be passed by reference through the IDL interface~\cite{janssen94ilu}. Objects in ILU are not merely static collections of data; as in OOP languages, object instances have a unique identity, may have methods, and those methods may be invoked anywhere a valid reference to the object is held, even from other languages.

ILU works much like Sun RPC, but adds a notion of \emph{modules}. In an application, there may be only one instance of a module, and a module has exactly one interface, specified in the IDL. Modules reside permanently in one address space, on one machine, and each module is written using one language. An application consists of a set of module instances.

In addition to regular procedures, modules may expose objects through their interface. Objects have a type, which is specified by another IDL interface with a set of methods. Object instances are owned by the module that exported the object's type. However, a \emph{reference} to the object may be obtained by other modules. This reference may be used to invoke the object's methods, which are executed via RPC to the owner module.

ILU provides a garbage collection scheme for objects. The module that owns an object instance is responsible for disposing of the object when there are no longer any references to the object. To manage this in ILU's distributed environment, ILU must arrange for the owner module to keep track of external modules holding references to its object, and periodically query them over the network to see if the reference is still held.

The ILU implementation supports modules written in Modula-3,
FORTRAN 77, C++, Lisp, and Python~\cite{janssen94ilu}.

\paragraph{XML-RPC}

XML-RPC~\cite{spec03xmlrpc} was designed to be a simple RPC protocol that would be easy to support from a number of languages. It uses an XML format instead of binary to represent a marshalled data, and provides two formats: one for function call requests and another for responses. XML-RPC does not provide a dedicated IDL; instead it describes a set of data representations in terms of XML, and expects implementations to define their own mapping from the language to those representations.

XML-RPC provides XML encodings for the usual primitive number, boolean, and character types, as well as variable-length strings and arrays of primitive types, and structures of arbitrary nested depth.

XML-RPC specifies an extra field in the response encoding, the presence of which indicates that an error occurred during the function execution. The interpretation of the error code depends on the implementation.

\paragraph{Web Services}

Web services are a general-purpose approach to ``distributed services''~\cite{spec00soap11,curbera02soap}. In practice, web services are used to provide RPC functionality on top of web protocols and standards like XML and HTTP.

The design of web services encompasses three orthogonal components required for distributed services. These are a communication protocol to encode data (analogous to a format for marshalled data in RPC), a way to describe services (analogous to IDLs), and a method for discovering services on the network.

SOAP is the most common communication protocol used in web services~\cite{spec00soap11, curbera02soap}. Like XML-RPC, it is based on XML, and describes formats for requests (function invocations) and responses (function returns). SOAP is more complex than XML-RPC, and specifies formats for meta-data like security credentials.

The XML standard has a specification, called XSD~\cite{biron04xsd}, for encoding primitive and structured data in an XML format. These include numbers, booleans, structures, arrays, and so on, as well as some higher-level types like dates and times. XSD also supports construction of new data types from this primitive set using sequencing, discriminated union, and restriction. This last mechanism is unique, and interesting: it specifies or restricts ranges of valid values that the underlying type may take. While decidedly more complex and verbose than the data encoding used by XML-RPC, XSD has the advantage that encoded data can be checked for correctness at runtime using XML processing tools that are available for a wide variety of platforms and languages. For example, integers can be verified to be within the representable range, strings can be checked to contain only valid Unicode characters, and so on.

A second XML format, called WSDL~\cite{curbera02soap} provides a way to describe the web service interface. WSDL, then, acts like the IDL in a traditional RPC mechanism. A WSDL specification defines a set of valid \emph{messages} in terms of XSD types. These messages are used by a set of \emph{ports}, each of which contains a set of \emph{operations}. Each operation describes a sequence of valid request and response messages. These operations might be similar to regular RPC semantics (i.e., a caller request, followed the callee's response), asynchronous messaging (i.g. just the request, with no response expected), or some other protocol entirely. WSDL therefore trades simplicity for flexibility; it can describe very complex protocols.

A WSDL description also contains a concrete binding, that tells the service what encoding and transport protocols to use (e.g., SOAP over HTTP). The concrete binding also maps operations to URLs, which gives them a globally unique endpoint for communication.

Like an IDL, the WSDL specification is processed through a tool that generates a skeleton for the implementation of the service in the desired target language. A stub implementation can also be generated from the WSDL. Typically, WSDL for a service is made available on the internet, and clients who wish to use the service may download the WSDL interface and generate stubs in the language of their choice.

While complex, the XML standards that web services are built upon are standardized and implemented in a wide variety of languages and systems.

\paragraph{Thrift}

Thrift~\cite{slee07thrift} is a recent RPC system developed at Facebook, with a focus on multi-language interoperability. It uses an IDL that, in addition to the usual primitive and structured types, includes data structures, such as maps and sets, common in modern ``scripting'' languages (e.g., Python, Ruby).

Thrift abstracts the marshalled representation of this data with a functional interface. So, marshalled data structures may be constructed or picked apart using and API with functions like \texttt{writeInt}, \texttt{writeStruct}, or \texttt{endStruct}. This API has been ported to C++, Java, Python, PHP, and Ruby, so Thrift can marshall data to and from a variety of languages.

Instead of using the API functions, most users of Thrift describe data structures in an IDL. The IDL is processed in the usual way, producing marshalling and unmarshalling routines for the desired language. These routines are generated with calls to the API. The benefit of this approach is that the API routines may be rewritten, and the underlying data representation altered, without requiring any changes to the client code.

The IDL can describe functions, and these have the same semantics as RPC. Functions that have no return value may be marked with the \texttt{async} keyword, which allows callers of that function to continue execution without waiting for the call to return.


%%
%% DISCUSSION
%%

\subsubsection{Discussion} 
\label{idl_discussion}

Relatively little effort is required, in general, to implement a mapping of a language's basic data types to those of an IDL, and to enable the IDL tools to generate stub and skeleton code for that language. This allows IDL-based approaches to multi-language programming to scale well -- if you have $n$ IDL-mapped languages, then you have $n^2$ language bindings, since any language in the set can interoperate with any other~\cite{kaplan98idl}.

The cost of this approach is a lack of specificity to any particular language and set of types. In particular, domain-specific data types (e.g., complex numbers, matrices, images, and so on), will need to be expressed in terms of the simple primitives and structures that most IDLs offer, and not the more natural high-level types that some languages may offer. IDLs cannot easily get around this limitation, because the types they define must constitute, in some sense, a \emph{lowest common denominator} type system across any and all languages that wish to participate~\cite{kaplan98idl}. If an IDL included say, a type for images, then each language would have to be able to decode that image type into meaningful data (or accept an incomplete mapping, but this defeats the purpose of interoperability). As we will see in Section~\ref{sec:background:typemap}, customizable \emph{type maps} can help to resolve this issue.

IDL-based interoperability systems usually require marshalling for complex types, even for communication between components written in the same language. Therefore, use of an IDL may be inefficient compared to other approaches.
