%!TEX root = twig-gpu.tex

\section{Related Work}

Numerous systems have been created in recent years to address the GPU programming problem that provide an abstraction above low level interfaces such as OpenCL or CUDA. These include the PGI Accelerate model\cite{pgi-accelerate} or the HMPP programming system\cite{hmpp}. While both of these systems provide an abstraction above the low level programming library, we believe that they hide too much from the programmer. There is little room for tuning of the way the lower level interface to the accelerator is used -- the programmer is reliant on the tool vendor to provide a sufficiently tunable abstraction such that working with this low level interface is unnecessary.

Furthermore, in large applications it is infeasible to assume that all developers of the various components will use the same higher level abstraction method. This makes it challenging not only to tune the code that bridges between devices, but to reason about how the code resulting from the independent programming systems interacts. We address this by adopting a code generation approach in which a single, low level target is used (such as OpenCL). This approach addresses both the composability problem (all Twig code maps to a single ``lingua franca'' for programming the hybrid system), and exposes the implementation in the generated code to allow tuning and modification by the end user. Thus, with Twig, users are free to adjust either the low level generated code, or the high level protocol logic, as required by the application.

The closest work to that which we describe is FIG\cite{fig}. In that work, a similar formal approach was taken specifically to the generate bindings between programs in two different programming languages. We have found that very similar issues arise in building bindings between devices in a hybrid system. These overlaps include memory ownership and management, data marshalling, and managing the flow of program control across the language or device boundary. Our work builds upon the approach in Fig, and aims to provide a general-purpose tool that is not tied to the Moby programming language. Twig's approach largely subsumes the case of foreign function interface generation, and could incorporate other interesting applications like mapping between two different libraries written in the same language. This second case is of particular interest when dealing with the problem of composing complex software from smaller program units, where developers working independently may have chosen different representations for data types that are semantically identical.

Kennedy's \emph{telescoping languages} work is related to ours in that it seeks to support high-level programming by deferring challenging problems to automated tools. In particular, the telescoping languages effort sought to provide the ability to build high-level problem-solving languages that used scripting languages to coordinate functionality present in domain-specific libraries\cite{kennedy00telescoping}. Much of the work then focused on compiler optimization methods and targeting potentially distributed, grid-based environments. Interestingly, one of these compilation techniques automated recognition and exploitation of identities. This would allow a compilation tool to recognize instances when compositions of functions could be replaced with more efficient equivalent implementations. As is described in this paper, we adopt a similar strategy in identifying compositions of rules that are equivalent to the identity function and can therefore be eliminated.

Code generation approaches have had notable success in the computational science field, an exemplar being the Tensor Contraction Engine (TCE)\cite{baumgartner05synthesis}. The TCE allows computational chemists to write tensor contraction operations in a high level language similar to Mathematica, leaving it up to the TCE tool to generate the corresponding collections of loops that implement the operations. The advantage of this approach is that tedious and often error-prone nested loops over many large arrays with a correspondingly large number of indices can be both machine generated and optimized. Optimizations such as loop fusion, memory locality management, and data distribution and partitioning in a parallel machine can all be automated, versus previous approaches that required very labor intensive hand written code. The TCE is not a general tool, and is only of use to programmers working with similar tensor-based computations.
