%!TEX root = twig.tex

\chapter{Future Work}

% If I were to keep working on this for the next 10 years...

There are a number of potential avenues for future research with
Twig.

\section{Implementation}

We presented our current implementation of Twig, called
\texttt{twigc}, in Chapter~\ref{ch:impl}. We are quite happy with
the overall design of the interpreter, and in particular with how
it we have embedded the core semantics in Haskell. There are still
many improvements and additional features we would like to
incorporate.

\subsection{Term-to-type Specification}

In order to generate C code, Twig needs to be configured with a
mapping from terms representing C types to the appropriate syntax
with which to declare variables of that type. For example, we have
terms such as \texttt{ptr(int)} which, in the generated C code,
must be declared like so:

\begin{verbatim}
int *x;
\end{verbatim}

Automatically generating casts in C presents a similar problem. In
our current implementation, \texttt{twigc} must be parameterized
with a list of pairs, matching terms to the C syntax of the type
they represent. So, users must provide a list like this one:

\begin{verbatim}
int = int
float = float
ptr(int) = int *
ptr(float) = float *
mystruct = struct MyStruct
\end{verbatim}

Providing this list quickly becomes tedious if there are lots of
user-defined types, or many types with recursive structure, or
both. There are a few possible solutions to this problem. One idea
is to add the ability for \texttt{twigc} to parse some structure
in the list, like so

\begin{verbatim}
int = int
float = float
ptr(X) = X *
\end{verbatim}

In this scheme, \texttt{X} is a variable that can be matched
against the appropriate term, and then substituted with the
appropriate syntax where necessary. This would make structured
types easier to specify. Another idea would be to provide a
built-in mapping for the basic C types, and then have Twig
automatically decide on a term structure for user-defined types.
For example, each \texttt{struct} in a header file could be mapped
to a term based on the structure name, e.g. \texttt{struct Foo}
would be mapped to the term \texttt{foo}. This would eliminate the
need for users to provide the term-to-type mapping, but would
reduce flexibility. In particular, users could not provide their
own term structure, which is sometimes useful (see the example in
Section~\ref{sec:eval:multi-lang}).

\subsection{Expression Reductions}
\label{sec:fw:twig-in-twig}

As we mentioned in Chapter~\ref{ch:reductions}, our current
implementation of expression reductions is ad hoc. We export the
Twig program and reduction rules as strings, parse and process
them in the Maude term rewriting system, and then import the
result back into Twig. In addition to making Twig dependent on an
external tool, this approach is potentially quite inefficient for
large programs. Instead, it would be both beneficial and
interesting to use Twig's own language to rewrite its expression
tree.

In principle, rewriting Twig expressions with Twig itself is easy
to do. Twig is based on System S, a core language for term
rewriting. It is simple to specify reduction rules -- they are
simply primitive rules in Twig. To apply the rules, we can exploit
Twig's ability to encode very general rewriting strategies. For
example, to perform a top-down rewrite, we could use an expression
such as

\begin{verbatim}
try(s) = s | T
repeat(s) = #fix(x, try(s ; x))
topdown(s) = #fix(x, s | #one(x))
reduce(s) = repeat(topdown(s))
\end{verbatim}

The expression \texttt{reduce} takes an expression argument
\texttt{s} and applies it to one term in a tree, searching in a
top-down fashion. It then repeats the procedure until no rewrites
are able to be applied, and returns the transformed tree.
Alternatively, we could specify a similar bottom-up strategy, or a
mix of the two.

Note that the strategies would require parameterized rules,
covered in Section~\ref{sec:fw:param-rules}, which are not
currently implemented in \texttt{twigc}.

\section{Theory}

The formal theory underlying Twig could be extended in a number of
ways.

\subsection{Environments and Conditional Rules}
\label{sec:fw:env}

System S has different ``levels'' of semantics for term rewriting,
corresponding to different levels of complexity and different
features. A feature, which Twig does not currently incorporate
into its own semantics, are the \emph{environment operators} of
System S. They environment operators are called \emph{match} and
\emph{build} -- they separate the operation of primitive rules
into two distinct phases. In the first phase, the term is matched
against an input pattern, and its variables are bound in an
environment. This environment is then passed along via expressions
and possibly extended. The environment is used to either build a
new term from its bound values and an output pattern, or else used
to test whether its bound values meet some condition. Essentially,
this feature would allow Twig to incorporate ``conditional''
rules, i.e. rules which only match if certain other rules have
matched before, as indicated by the environment.

This would be a relatively straightforward addition to the
semantics, since it would follow System S fairly closely, and
would not require extensive modification to accommodate our
extended code generation semantics.

\subsection{Parameterized Rules}
\label{sec:fw:param-rules}

In System S, expressions are first-order. That is, they may be
parameterized by other expressions. In Twig, parameterized
expressions might look like this:

\begin{verbatim}
try(s) = s | T
\end{verbatim}

This statement creates a rule called \texttt{try} which is
parameterized by an expression \texttt{s}. To invoke \texttt{try},
an expression must be passed as its argument, like so:

\begin{verbatim}
foo = [foo -> bar] <<< ... >>>

main = try(foo)
\end{verbatim}

Here, \texttt{foo} is a primitive rule, but it could be any Twig
expression.

Parameterized expressions would facilitate reuse and modularity.
They turn out to be somewhat tricky to implement, since we must
ensure that circular references are not introduced. We can solve
this problem by stipulating that expressions must be defined
before they are referenced, and that expressions may not reference
themselves.

\subsection{Code Generation}
\label{sec:fw:code-gen}

Our current model for code generation is intentionally abstract,
in the sense that it does not assume very much about the languages
it might be used to generate. The abstraction is a feature -- it
allows Twig to be used to generate different languages without
altering its core semantics. However, there are certain features
that, in our experience, would make code generation more
convenient.

First, we often write primitive rules that allocate memory. It
would be nice if the code generation model allowed for ``closing
blocks,'' i.e. a way to call some tear down code at the end of the
generated code's lifetime. Clearly, this is a difficult problem in
general, since it may not always be clear when objects should be
deallocated or files closed. Still, one could imagine rules like
the following being useful:

\begin{verbatim}
alloc_array = [int -> array(int)] <<<
  $out = malloc($in * sizeof(int));
>>><<<
  free($out);
>>>
\end{verbatim}

In this (invented) syntax, Twig would automatically insert the
second block wherever it determines that the variable generated
for \texttt{\$out} goes out of scope. One challenge with
supporting such a syntax would be incorporating it into the
abstract model.

\subsection{Higher-order Rules}
\label{sec:fw:hor}

In many cases, Twig could generate much more complex kinds of code
if we could parameterize primitive rules with expressions.
Essentially, this would make rules higher-order. This idea is
somewhat different than the parameterized expressions presented in
Section~\ref{sec:fw:param-rules}, which would make expressions
first-order.

Higher-order rules would allow Twig to generate code that takes
context into account. For example, the following rule (using a
made-up syntax), would transform an array of elements of type $X$
to an array of elements of type $Y$, given another transformation
named $s$ that transforms $X$ to $Y$.

\begin{verbatim}
map = [array(X) -> array(Y) | s : X -> Y] <<<
  $out = malloc(N * sizeof($Y));
  for(int i = 0; i < N; i++) {
    $out[i] = $s($in[i]);
  }
>>>
\end{verbatim}

The example implements the familiar \emph{map} function, common in
functional programming languages.

\subsection{Expression Reductions}
\label{sec:fw:expr-red}

Currently, expression reductions are not formalized with the same
degree of rigor as the rest of Twig's semantics. In particular, we
rely on our implementation to decide how Twig rewrites
expressions. These details could matter in practice. For example
consider the directives:

\begin{verbatim}
@reduce foo => bar
@reduce foo;foo => baz
\end{verbatim}

Clearly, these reductions are ambiguous in the absence of a formal
description of how they will be applied. This is because the rules
are not confluent.

Twig will currently send both rules, in the order given, to Maude.
At that point we defer to Maude's implementation. Currently Twig
side-steps this problem by simply insisting that expression
reductions should be confluent, and that the result is undefined
if they are not. However, if the system was formalized, or if we
allowed users to specify rewriting strategies, we could allow for
non-confluent rules. 

In addition, we think it would be quite useful to allow for
variables in expression reductions, allowing users to write
directives such as

\begin{verbatim}
@reduce foo;X;bar => foo
\end{verbatim}

or

\begin{verbatim}
@reduce X;foo;Y => X;Y
\end{verbatim}

This would greatly increase the flexibility and reusability of
reduction directives.
